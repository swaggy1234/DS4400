{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d99fb36-2662-49d2-88a1-0f1354fa30f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metrics table ===\n",
      "   alpha  iters      Train MSE      Train R^2       Test MSE       Test R^2\n",
      "0   0.01     10   2.357503e+11  -1.047561e+00   2.829701e+11  -6.972070e-01\n",
      "1   0.01     50   6.972838e+10   3.943887e-01   9.431447e+10   4.343178e-01\n",
      "2   0.01    100   3.662532e+10   6.818984e-01   6.116358e+10   6.331512e-01\n",
      "3   0.10     10   3.489608e+10   6.969173e-01   5.987407e+10   6.408854e-01\n",
      "4   0.10     50   3.105631e+10   7.302669e-01   5.844631e+10   6.494489e-01\n",
      "5   0.10    100   3.104372e+10   7.303762e-01   5.839468e+10   6.497586e-01\n",
      "6   0.50     10   2.536034e+23  -2.202620e+12   2.800745e+23  -1.679840e+12\n",
      "7   0.50     50   2.604548e+74  -2.262126e+63   2.876411e+74  -1.725223e+63\n",
      "8   0.50    100  1.514273e+138 -1.315190e+127  1.672333e+138 -1.003037e+127\n",
      "\n",
      "=== Theta summary ===\n",
      "   alpha  iters        theta0    theta_norm  \\\n",
      "0   0.01     10  9.519802e+04  1.221649e+05   \n",
      "1   0.01     50  3.308955e+05  3.633711e+05   \n",
      "2   0.01    100  4.513976e+05  4.824453e+05   \n",
      "3   0.10     10  4.645357e+05  4.954186e+05   \n",
      "4   0.10     50  5.204074e+05  5.544669e+05   \n",
      "5   0.10    100  5.204148e+05  5.552055e+05   \n",
      "6   0.50     10  5.204148e+05  2.178932e+11   \n",
      "7   0.50     50 -1.439034e+21  6.982848e+36   \n",
      "8   0.50    100 -1.150765e+53  5.324373e+68   \n",
      "\n",
      "                                        theta_first5  \n",
      "0  [95198.0248, -760.6055, 11902.3897, 20247.7364...  \n",
      "1  [330895.5304, 2153.5262, 6074.7809, 23905.8693...  \n",
      "2  [451397.6498, 5405.373, -3858.5959, 19034.6222...  \n",
      "3  [464535.7167, 5747.657, -4826.691, 18503.0482,...  \n",
      "4  [520407.4064, 8674.6401, -14276.2085, 17229.53...  \n",
      "5  [520414.8339, 8800.549, -14489.1119, 18257.307...  \n",
      "6  [520414.834, 3243649662.2918, -51936723824.532...  \n",
      "7  [-1.439033728649684e+21, 1.039472468243546e+35...  \n",
      "8  [-1.1507646254396955e+53, 7.92590471528213e+66...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "target = \"price\"\n",
    "\n",
    "# One-hot encode and align columns (same as Problem 2/3)\n",
    "X_train = pd.get_dummies(train_df.drop(columns=[target]), drop_first=True)\n",
    "X_test  = pd.get_dummies(test_df.drop(columns=[target]), drop_first=True)\n",
    "X_train, X_test = X_train.align(X_test, join=\"left\", axis=1, fill_value=0)\n",
    "\n",
    "y_train = train_df[target].to_numpy(dtype=float)\n",
    "y_test  = test_df[target].to_numpy(dtype=float)\n",
    "\n",
    "Xtr = X_train.to_numpy(dtype=float)\n",
    "Xte = X_test.to_numpy(dtype=float)\n",
    "\n",
    "# Feature scaling it should be important for GD stability\n",
    "mu = Xtr.mean(axis=0)\n",
    "sigma = Xtr.std(axis=0)\n",
    "sigma[sigma == 0] = 1.0\n",
    "Xtr_s = (Xtr - mu) / sigma\n",
    "Xte_s = (Xte - mu) / sigma\n",
    "\n",
    "# Add bias term\n",
    "Xtr_b = np.c_[np.ones((Xtr_s.shape[0], 1)), Xtr_s]\n",
    "Xte_b = np.c_[np.ones((Xte_s.shape[0], 1)), Xte_s]\n",
    "\n",
    "def gradient_descent(Xb, y, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Batch GD using lecture gradient:\n",
    "    grad = (2/N) * X^T (X theta - y)\n",
    "    \"\"\"\n",
    "    N, d = Xb.shape\n",
    "    theta = np.zeros(d, dtype=float)\n",
    "    for _ in range(num_iters):\n",
    "        preds = Xb @ theta\n",
    "        grad = (2.0 / N) * (Xb.T @ (preds - y))\n",
    "        theta -= alpha * grad\n",
    "    return theta\n",
    "\n",
    "def evaluate(Xb, y, theta):\n",
    "    preds = Xb @ theta\n",
    "    return mean_squared_error(y, preds), r2_score(y, preds)\n",
    "\n",
    "alphas = [0.01, 0.1, 0.5]\n",
    "iters_list = [10, 50, 100]\n",
    "\n",
    "metric_rows = []\n",
    "theta_rows = []\n",
    "\n",
    "for a in alphas:\n",
    "    for it in iters_list:\n",
    "        theta = gradient_descent(Xtr_b, y_train, a, it)\n",
    "        tr_mse, tr_r2 = evaluate(Xtr_b, y_train, theta)\n",
    "        te_mse, te_r2 = evaluate(Xte_b, y_test, theta)\n",
    "\n",
    "        metric_rows.append({\n",
    "            \"alpha\": a, \"iters\": it,\n",
    "            \"Train MSE\": tr_mse, \"Train R^2\": tr_r2,\n",
    "            \"Test MSE\": te_mse, \"Test R^2\": te_r2\n",
    "        })\n",
    "\n",
    "        # reporting theta (vector is huge, so summarize)\n",
    "        theta_rows.append({\n",
    "            \"alpha\": a, \"iters\": it,\n",
    "            \"theta0\": theta[0],\n",
    "            \"theta_norm\": np.linalg.norm(theta),\n",
    "            \"theta_first5\": np.round(theta[:5], 4).tolist()\n",
    "        })\n",
    "\n",
    "gd_metrics = pd.DataFrame(metric_rows).sort_values([\"alpha\",\"iters\"]).reset_index(drop=True)\n",
    "gd_theta   = pd.DataFrame(theta_rows).sort_values([\"alpha\",\"iters\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"=== Metrics table ===\")\n",
    "print(gd_metrics)\n",
    "\n",
    "print(\"\\n=== Theta summary ===\")\n",
    "print(gd_theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116b64f-1146-4af5-8c9f-aeb295baecd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
