{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8c48d7-e246-497f-aab8-8b7d7e4c7069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "Saved: train_clean.csv\n",
      "Saved: test_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ============================================\n",
    "# Configuration\n",
    "# ============================================\n",
    "\n",
    "DROP_COLS = [\"id\", \"date\", \"zipcode\"]\n",
    "TARGET = \"price\"\n",
    "\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE  = \"test.csv\"\n",
    "\n",
    "TRAIN_OUT = \"train_clean.csv\"\n",
    "TEST_OUT  = \"test_clean.csv\"\n",
    "\n",
    "# ============================================\n",
    "# 1. Load raw train and test\n",
    "# ============================================\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_FILE)\n",
    "test_df  = pd.read_csv(TEST_FILE)\n",
    "\n",
    "# ============================================\n",
    "# 2. Drop ignored columns (if they exist)\n",
    "# ============================================\n",
    "\n",
    "train_df = train_df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "test_df  = test_df.drop(columns=DROP_COLS, errors=\"ignore\")\n",
    "\n",
    "# ============================================\n",
    "# 3. Divide price by 1000\n",
    "# ============================================\n",
    "\n",
    "train_df[TARGET] = train_df[TARGET].astype(float) / 1000.0\n",
    "test_df[TARGET]  = test_df[TARGET].astype(float) / 1000.0\n",
    "\n",
    "# ============================================\n",
    "# 4. Separate features and target\n",
    "# ============================================\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]\n",
    "\n",
    "X_test  = test_df.drop(columns=[TARGET])\n",
    "y_test  = test_df[TARGET]\n",
    "\n",
    "# ============================================\n",
    "# 5. Scale features (using TRAIN stats only)\n",
    "# ============================================\n",
    "\n",
    "mu = X_train.mean()\n",
    "sigma = X_train.std()\n",
    "\n",
    "# Prevent division by zero\n",
    "sigma[sigma == 0] = 1.0\n",
    "\n",
    "X_train_scaled = (X_train - mu) / sigma\n",
    "X_test_scaled  = (X_test - mu) / sigma\n",
    "\n",
    "# ============================================\n",
    "# 6. Reconstruct cleaned DataFrames\n",
    "# ============================================\n",
    "\n",
    "train_clean = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "test_clean  = pd.concat([X_test_scaled, y_test], axis=1)\n",
    "\n",
    "# ============================================\n",
    "# 7. Save cleaned CSV files\n",
    "# ============================================\n",
    "\n",
    "train_clean.to_csv(TRAIN_OUT, index=False)\n",
    "test_clean.to_csv(TEST_OUT, index=False)\n",
    "\n",
    "print(\"Preprocessing complete.\")\n",
    "print(\"Saved:\", TRAIN_OUT)\n",
    "print(\"Saved:\", TEST_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2deb804-2313-49e9-889c-c23f08ef4c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
